name: CI

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  api:
    name: API - Build & Test
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Display Python version
        run: python --version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install pytest-cov
        run: python -m pip install pytest-cov==5.0.0 --no-cache-dir

      - name: Alembic heads preflight (single-head guard)
        run: |
          set -euo pipefail
          heads=$(alembic heads -q || true)
          count=$(printf "%s\n" "$heads" | sed '/^$/d' | wc -l | tr -d ' ')
          if [ "$count" -gt 1 ]; then
            echo "❌ Multiple Alembic heads detected ($count). Merge heads before running migration tests."
            echo "Heads:"
            printf "%s\n" "$heads"
            exit 1
          fi
          echo "✅ Alembic head OK: ${heads}"

      - name: Lint (syntax guard)
        run: |
          python -m pip install ruff==0.6.5
          ruff check app tests --select E9

      - name: Guard boolean defaults in migrations
        run: |
          set -euo pipefail
          if rg -n "Boolean\\(\\).*server_default=(sa.text\\(\\\"[01]\\\"\\)|\\\"[01]\\\")|BOOLEAN DEFAULT [01]" alembic; then
            echo "❌ Boolean defaults must use true/false, not 0/1."
            exit 1
          fi

      - name: Run unit tests with coverage
        working-directory: .
        run: |
          # Run tests excluding smoke and postgres markers (unit tests that work with SQLite)
          # Also ignore smoke folder entirely as belt-and-suspenders
          pytest -v -m "not smoke and not postgres" --ignore=backend/tests/smoke --tb=short --cov=backend/app --cov-report=xml --cov-report=term
        env:
          # CI-safe environment variables (no secrets)
          APP_ENV: "dev"
          TESTING: "true"
          DATABASE_URL: "sqlite+aiosqlite:///:memory:"
          PYTHONPATH: "backend"

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-coverage
          path: coverage.xml

  web:
    name: Web - Build
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: web

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc

      - name: Display Node version
        run: node --version

      - name: Verify Node runtime matches .nvmrc
        run: |
          expected=$(cat ../.nvmrc)
          actual=$(node --version | sed 's/^v//')
          if [ "$actual" != "$expected" ]; then
            echo "Node version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache npm dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('web/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install dependencies
        run: npm ci

      - name: Typecheck
        run: npx tsc --noEmit

      - name: Lint (if available)
        run: npm run lint --if-present

      - name: Build application
        run: npm run build
        env:
          # CI-safe environment variable for Next.js build
          NEXT_PUBLIC_API_BASE_URL: "http://localhost:8000"

  api-prod-config:
    name: API - Prod Config Validation
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate prod config requirements
        run: |
          python -c "from app.settings import Settings; s = Settings(); print(f'✓ Prod config validation passed: APP_ENV={s.app_env}')"
        env:
          # Prod mode with CI-safe dummy secrets (validates prod enforcement still works)
          APP_ENV: "prod"
          TESTING: "false"
          AUTH_SECRET_KEY: "ci-auth-secret-not-default-12345678"
          CLIENT_PORTAL_SECRET: "ci-client-secret-not-default-12345678"
          WORKER_PORTAL_SECRET: "ci-worker-secret-not-default-12345678"
          METRICS_ENABLED: "false"
          STRICT_CORS: "false"

  security:
    name: Security - Bandit Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat .python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Install Bandit
        run: python -m pip install bandit==1.7.9 --no-cache-dir

      - name: Run Bandit (high severity)
        run: |
          set -o pipefail
          bandit -r backend/app --severity-level high -f json -o bandit-report.json --exit-zero 2>&1 | tee bandit.log
          status=${PIPESTATUS[0]}
          if [ ! -f bandit-report.json ]; then
            echo '{"error":"bandit failed. See bandit.log"}' > bandit-report.json
          fi
          exit "$status"

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: |
            bandit-report.json
            bandit.log

  rls-audit:
    name: Security - RLS Coverage Audit
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend
    env:
      DATABASE_URL: postgresql+psycopg://postgres:postgres@localhost:5432/cleaning
      APP_ENV: dev
      TESTING: true
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: cleaning
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m pip install "alembic>=1.13"

      - name: Apply migrations
        run: python -m alembic -c alembic_rls_audit.ini upgrade head

      - name: Run RLS coverage audit
        run: |
          python scripts/audit_rls_coverage.py --output rls-audit.md --fail-on-core-missing

      - name: Upload RLS audit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rls-audit-report
          path: backend/rls-audit.md

  container-scan:
    name: Security - Trivy Image Scan
    runs-on: ubuntu-latest
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot
      TRIVY_IGNORE_UNFIXED: "true"
      TRIVY_SEVERITY: "CRITICAL,HIGH"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build api and web images
        run: docker compose build api web

      - name: Capture built image IDs
        run: |
          API_IMAGE_ID=$(docker image inspect -f '{{.Id}}' cleanwithsnapshot-api:ci)
          WEB_IMAGE_ID=$(docker image inspect -f '{{.Id}}' cleanwithsnapshot-web:ci)
          if [ -z "${API_IMAGE_ID}" ] || [ -z "${WEB_IMAGE_ID}" ]; then
            echo "Failed to resolve image IDs. api=${API_IMAGE_ID} web=${WEB_IMAGE_ID}"
            exit 1
          fi
          echo "API_IMAGE_ID=${API_IMAGE_ID}" >> "$GITHUB_ENV"
          echo "WEB_IMAGE_ID=${WEB_IMAGE_ID}" >> "$GITHUB_ENV"
          {
            echo "api cleanwithsnapshot-api:ci ${API_IMAGE_ID}"
            echo "web cleanwithsnapshot-web:ci ${WEB_IMAGE_ID}"
            docker image inspect --format='{{.RepoTags}} {{.Id}}' cleanwithsnapshot-api:ci
            docker image inspect --format='{{.RepoTags}} {{.Id}}' cleanwithsnapshot-web:ci
          } > built-image-ids.txt

      - name: Verify api image wheel/jaraco versions
        run: |
          docker run --rm cleanwithsnapshot-api:ci \
            python -c "import importlib.metadata as m; print('wheel', m.version('wheel')); print('jaraco.context', m.version('jaraco.context'))"

      - name: Inspect api image site-packages for duplicates
        run: |
          docker run --rm cleanwithsnapshot-api:ci \
            python -c "import sys, importlib.metadata as m; print('sys.path:', *sys.path, sep='\\n  '); print('wheel:', m.version('wheel')); print('jaraco.context:', m.version('jaraco.context'))"
          docker run --rm cleanwithsnapshot-api:ci sh -lc "\
            set -e; \
            echo '=== FIND wheel/jaraco dist-info ==='; \
            find / -type d \\( -name 'wheel-*.dist-info' -o -name 'jaraco.context-*.dist-info' \\) 2>/dev/null | sort | sed 's/^/FOUND: /'; \
            echo '=== DONE ==='"

      - name: Install Trivy CLI
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

      - name: Scan api image (Trivy)
        continue-on-error: true
        run: |
          trivy image \
            --format json \
            --output trivy-cleanwithsnapshot-api.json \
            --scanners vuln \
            --severity "${TRIVY_SEVERITY}" \
            --ignore-unfixed \
            cleanwithsnapshot-api:ci

      - name: Scan web image (Trivy)
        continue-on-error: true
        run: |
          trivy image \
            --format json \
            --output trivy-cleanwithsnapshot-web.json \
            --scanners vuln \
            --severity "${TRIVY_SEVERITY}" \
            --ignore-unfixed \
            cleanwithsnapshot-web:ci
      
      - name: Dump API Trivy HIGH/CRITICAL (top)
        if: always()
        run: |
          python - <<'PY'
          import json
          from pathlib import Path
          p = Path("trivy-cleanwithsnapshot-api.json")
          if not p.exists():
              print("missing report", p)
              raise SystemExit(0)
          d = json.loads(p.read_text())
          vulns = []
          for r in d.get("Results", []) or []:
              for v in (r.get("Vulnerabilities") or []):
                  vulns.append({
                      "Target": r.get("Target"),
                      "Pkg": v.get("PkgName"),
                      "Installed": v.get("InstalledVersion"),
                      "Fixed": v.get("FixedVersion"),
                      "Severity": v.get("Severity"),
                      "VulnID": v.get("VulnerabilityID"),
                      "Title": v.get("Title"),
                  })
          vulns = [x for x in vulns if x["Severity"] in ("CRITICAL","HIGH")]
          vulns.sort(key=lambda x: (x["Severity"]!="CRITICAL", x["Pkg"] or "", x["VulnID"] or ""))
          print(f"HIGH/CRITICAL count: {len(vulns)}")
          for x in vulns[:30]:
              print(f'{x["Severity"]} {x["VulnID"]} {x["Pkg"]} {x["Installed"]} -> {x["Fixed"]} target={x["Target"]}')
          PY

      - name: Summarize Trivy results
        if: always()
        continue-on-error: true
        run: |
          python - <<'PY'
          import json
          import sys
          from pathlib import Path
          from collections import Counter

          reports = {
              "api": Path("trivy-cleanwithsnapshot-api.json"),
              "web": Path("trivy-cleanwithsnapshot-web.json"),
          }
          missing = []

          def count_by_severity(data):
              counts = {sev: 0 for sev in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]}
              for result in data.get("Results", []):
                  for vuln in result.get("Vulnerabilities", []) or []:
                      severity = vuln.get("Severity")
                      if severity in counts:
                          counts[severity] += 1
              return counts

          for label, path in reports.items():
              if not path.exists():
                  print(f"Error: no Trivy report found for {label} at {path}.")
                  missing.append(label)
                  continue
              with path.open() as handle:
                  data = json.load(handle)
              counts = count_by_severity(data)
              print(f"Trivy summary for {label}:")
              for severity in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]:
                  print(f"{severity}: {counts[severity]}")
              packages = Counter()
              for result in data.get("Results", []):
                  for vuln in result.get("Vulnerabilities", []) or []:
                      pkg = vuln.get("PkgName")
                      if pkg:
                          packages[pkg] += 1
              if packages:
                  print("Top 10 packages by vulnerability count:")
                  for name, count in packages.most_common(10):
                      print(f"{name}: {count}")
              else:
                  print("Top 10 packages by vulnerability count: none found")
          if missing:
              sys.exit(2)
          sys.exit(0)
          PY

      - name: Upload Trivy reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: trivy-reports
          path: |
            trivy-cleanwithsnapshot-*.json
            built-image-ids.txt

      - name: Fail if Trivy gate hit (HIGH/CRITICAL)
        if: always()
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          reports = [
              Path("trivy-cleanwithsnapshot-api.json"),
              Path("trivy-cleanwithsnapshot-web.json"),
          ]

          truthy = {"1", "true", "yes", "on"}
          ignore_unfixed = os.getenv("TRIVY_IGNORE_UNFIXED", "false").strip().lower() in truthy

          def status_indicates_fix(status: str) -> bool:
              if not status:
                  return False
              return status.strip().lower() == "fixed"

          def status_indicates_no_fix(status: str) -> bool:
              if not status:
                  return False
              return status.strip().lower() in {"affected", "will_not_fix", "unfixed", "not_fixed", "unknown"}

          def summarize_report(report: Path) -> tuple[int, int, list[dict]]:
              if not report.exists():
                  print(f"Error: missing Trivy report {report}")
                  return 0, 0, []
              data = json.loads(report.read_text())
              total = 0
              fixable = 0
              details = []
              for result in data.get("Results", []) or []:
                  for vuln in (result.get("Vulnerabilities") or []):
                      severity = vuln.get("Severity")
                      if severity not in ("CRITICAL", "HIGH"):
                          continue
                      total += 1
                      fixed = (vuln.get("FixedVersion") or "").strip()
                      status = (vuln.get("Status") or "").strip()
                      fixable_hit = True
                      if ignore_unfixed:
                          if status_indicates_no_fix(status):
                              fixable_hit = False
                          else:
                              fixable_hit = bool(fixed or status_indicates_fix(status))
                      if fixable_hit:
                          fixable += 1
                      details.append(
                          {
                              "PkgName": vuln.get("PkgName"),
                              "InstalledVersion": vuln.get("InstalledVersion"),
                              "FixedVersion": vuln.get("FixedVersion"),
                              "VulnerabilityID": vuln.get("VulnerabilityID"),
                              "Severity": severity,
                          }
                      )
              return total, fixable, details

          missing_reports = [p for p in reports if not p.exists()]
          if missing_reports:
              print("Missing Trivy reports:", ", ".join(str(p) for p in missing_reports))
              raise SystemExit(2)

          overall_fixable = 0
          for report in reports:
              total, fixable, details = summarize_report(report)
              overall_fixable += fixable
              print(f"Trivy gate summary for {report}:")
              print(f"  HIGH/CRITICAL total: {total}")
              print(f"  Fixable HIGH/CRITICAL (gate): {fixable}")
              for entry in sorted(
                  details,
                  key=lambda d: (d["Severity"] != "CRITICAL", d["PkgName"] or "", d["VulnerabilityID"] or ""),
              )[:10]:
                  print(
                      "  "
                      f'{entry["Severity"]} {entry["VulnerabilityID"]} '
                      f'{entry["PkgName"]} {entry["InstalledVersion"]} -> {entry["FixedVersion"]}'
                  )

          raise SystemExit(1 if overall_fixable else 0)
          PY


  secrets-scan:
    name: Security - Secrets Scan (Gitleaks)
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  infra:
    name: Infrastructure - Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create ephemeral .env for compose validation
        run: |
          cat > .env <<'EOF'
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          EOF

      - name: Validate docker-compose.yml
        run: |
          echo "Validating docker-compose configuration..."
          docker compose config > /dev/null
          echo "✓ docker-compose.yml is valid"

      - name: Cleanup ephemeral .env
        run: rm -f .env

      - name: Check for shell scripts
        run: |
          if [ -d "ops" ]; then
            echo "Checking bash scripts in ops/..."
            find ops -name "*.sh" -type f -exec bash -n {} \; -print
            echo "✓ All bash scripts have valid syntax"
          else
            echo "ℹ No ops/ directory found, skipping bash validation"
          fi

  smoke-compose:
    name: Smoke - Docker Compose
    runs-on: ubuntu-latest
    needs: [api, web]
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot-ci

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create CI .env for compose
        run: |
          cat > .env <<'EOF'
          APP_ENV=dev
          TESTING=true
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          DATABASE_URL=postgresql+psycopg://postgres:postgres@db:5432/cleaning
          NEXT_PUBLIC_API_BASE_URL=http://api:8000
          EOF

      - name: Start Docker Compose stack (smoke)
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d --wait db redis api web

      - name: Run smoke tests
        run: ./ops/smoke.sh
        env:
          API_BASE_URL: http://localhost:8000
          WEB_BASE_URL: http://localhost:3000

      - name: Capture compose logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml ps > compose-ps.txt
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --no-color > compose.log

      - name: Upload compose logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: compose-smoke-logs
          path: |
            compose.log
            compose-ps.txt

      - name: Tear down Docker Compose stack
        if: always()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v

      - name: Cleanup CI .env
        if: always()
        run: rm -f .env

  perf-baseline:
    name: Performance - Baseline Comparison (Warn-only)
    runs-on: ubuntu-latest
    if: ${{ secrets.PERF_BASE_URL != '' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Install k6
        uses: grafana/setup-k6-action@v1

      - name: Run healthz load test + baseline compare
        env:
          BASE_URL: ${{ secrets.PERF_BASE_URL }}
        run: |
          k6 run --no-thresholds --summary-export k6-healthz.json load-tests/k6/healthz.js
          python load-tests/compare_baseline.py --scenario healthz --results k6-healthz.json --mode warn

      - name: Run admin load test + baseline compare
        env:
          BASE_URL: ${{ secrets.PERF_BASE_URL }}
          ADMIN_USER: ${{ secrets.PERF_ADMIN_USER }}
          ADMIN_PASSWORD: ${{ secrets.PERF_ADMIN_PASSWORD }}
          ADMIN_AUTH_HEADER: ${{ secrets.PERF_ADMIN_AUTH_HEADER }}
        run: |
          if [ -z "${ADMIN_AUTH_HEADER:-}" ] && { [ -z "${ADMIN_USER:-}" ] || [ -z "${ADMIN_PASSWORD:-}" ]; }; then
            echo "Skipping admin_list scenario: admin credentials not provided."
            exit 0
          fi
          k6 run --no-thresholds --summary-export k6-admin.json load-tests/k6/admin_list.js
          python load-tests/compare_baseline.py --scenario admin_list --results k6-admin.json --mode warn

      - name: Run booking flow load test + baseline compare
        env:
          BASE_URL: ${{ secrets.PERF_BASE_URL }}
          BOOKING_CAPTCHA_TOKEN: ${{ secrets.PERF_BOOKING_CAPTCHA_TOKEN }}
        run: |
          k6 run --no-thresholds --summary-export k6-booking.json load-tests/k6/booking_flow.js
          python load-tests/compare_baseline.py --scenario booking_flow --results k6-booking.json --mode warn
