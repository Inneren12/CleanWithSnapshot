name: CI

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  api:
    name: API - Build & Test
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Display Python version
        run: python --version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install pytest-cov
        run: python -m pip install pytest-cov==5.0.0 --no-cache-dir

      - name: Lint (syntax guard)
        run: |
          python -m pip install ruff==0.6.5
          ruff check app tests --select E9

      - name: Run unit tests with coverage
        working-directory: .
        run: |
          # Run tests excluding smoke and postgres markers (unit tests that work with SQLite)
          # Also ignore smoke folder entirely as belt-and-suspenders
          pytest -v -m "not smoke and not postgres" --ignore=backend/tests/smoke --tb=short --cov=backend/app --cov-report=xml --cov-report=term
        env:
          # CI-safe environment variables (no secrets)
          APP_ENV: "dev"
          TESTING: "true"
          DATABASE_URL: "sqlite+aiosqlite:///:memory:"
          PYTHONPATH: "backend"

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-coverage
          path: coverage.xml

  web:
    name: Web - Build
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: web

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc

      - name: Display Node version
        run: node --version

      - name: Verify Node runtime matches .nvmrc
        run: |
          expected=$(cat ../.nvmrc)
          actual=$(node --version | sed 's/^v//')
          if [ "$actual" != "$expected" ]; then
            echo "Node version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache npm dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('web/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install dependencies
        run: npm ci

      - name: Typecheck
        run: npx tsc --noEmit

      - name: Lint (if available)
        run: npm run lint --if-present

      - name: Build application
        run: npm run build
        env:
          # CI-safe environment variable for Next.js build
          NEXT_PUBLIC_API_BASE_URL: "http://localhost:8000"

  api-prod-config:
    name: API - Prod Config Validation
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate prod config requirements
        run: |
          python -c "from app.settings import Settings; s = Settings(); print(f'✓ Prod config validation passed: APP_ENV={s.app_env}')"
        env:
          # Prod mode with CI-safe dummy secrets (validates prod enforcement still works)
          APP_ENV: "prod"
          TESTING: "false"
          AUTH_SECRET_KEY: "ci-auth-secret-not-default-12345678"
          CLIENT_PORTAL_SECRET: "ci-client-secret-not-default-12345678"
          WORKER_PORTAL_SECRET: "ci-worker-secret-not-default-12345678"
          METRICS_ENABLED: "false"
          STRICT_CORS: "false"

  security:
    name: Security - Bandit Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat .python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Install Bandit
        run: python -m pip install bandit==1.7.9 --no-cache-dir

      - name: Run Bandit (high severity)
        run: |
          set -o pipefail
          bandit -r backend/app --severity-level high -f json -o bandit-report.json --exit-zero 2>&1 | tee bandit.log
          status=${PIPESTATUS[0]}
          if [ ! -f bandit-report.json ]; then
            echo '{"error":"bandit failed. See bandit.log"}' > bandit-report.json
          fi
          exit "$status"

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: |
            bandit-report.json
            bandit.log

  container-scan:
    name: Security - Trivy Image Scan
    runs-on: ubuntu-latest
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build api and web images
        run: docker compose build api web

      - name: Scan api image (Trivy)
        uses: aquasecurity/trivy-action@0.29.0
        continue-on-error: true
        with:
          image-ref: cleanwithsnapshot-api
          format: json
          output: trivy-cleanwithsnapshot-api.json
          scanners: vuln
          severity: CRITICAL,HIGH
          ignore-unfixed: true
          exit-code: ${{ github.event_name == 'pull_request' && '0' || '1' }}

      - name: Scan web image (Trivy)
        uses: aquasecurity/trivy-action@0.29.0
        continue-on-error: true
        with:
          image-ref: cleanwithsnapshot-web
          format: json
          output: trivy-cleanwithsnapshot-web.json
          scanners: vuln
          severity: CRITICAL,HIGH
          ignore-unfixed: true
          exit-code: ${{ github.event_name == 'pull_request' && '0' || '1' }}
      
      - name: Dump API Trivy HIGH/CRITICAL (top)
        if: always()
        run: |
          python - <<'PY'
          import json
          from pathlib import Path
          p = Path("trivy-cleanwithsnapshot-api.json")
          if not p.exists():
              print("missing report", p)
              raise SystemExit(0)
          d = json.loads(p.read_text())
          vulns = []
          for r in d.get("Results", []) or []:
              for v in (r.get("Vulnerabilities") or []):
                  vulns.append({
                      "Target": r.get("Target"),
                      "Pkg": v.get("PkgName"),
                      "Installed": v.get("InstalledVersion"),
                      "Fixed": v.get("FixedVersion"),
                      "Severity": v.get("Severity"),
                      "VulnID": v.get("VulnerabilityID"),
                      "Title": v.get("Title"),
                  })
          vulns = [x for x in vulns if x["Severity"] in ("CRITICAL","HIGH")]
          vulns.sort(key=lambda x: (x["Severity"]!="CRITICAL", x["Pkg"] or "", x["VulnID"] or ""))
          print(f"HIGH/CRITICAL count: {len(vulns)}")
          for x in vulns[:30]:
              print(f'{x["Severity"]} {x["VulnID"]} {x["Pkg"]} {x["Installed"]} -> {x["Fixed"]} target={x["Target"]}')
          PY

      - name: Summarize Trivy results
        if: always()
        continue-on-error: true
        run: |
          python - <<'PY'
          import json
          import sys
          from pathlib import Path
          from collections import Counter

          reports = {
              "api": Path("trivy-cleanwithsnapshot-api.json"),
              "web": Path("trivy-cleanwithsnapshot-web.json"),
          }
          missing = []

          def count_by_severity(data):
              counts = {sev: 0 for sev in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]}
              for result in data.get("Results", []):
                  for vuln in result.get("Vulnerabilities", []) or []:
                      severity = vuln.get("Severity")
                      if severity in counts:
                          counts[severity] += 1
              return counts

          for label, path in reports.items():
              if not path.exists():
                  print(f"Error: no Trivy report found for {label} at {path}.")
                  missing.append(label)
                  continue
              with path.open() as handle:
                  data = json.load(handle)
              counts = count_by_severity(data)
              print(f"Trivy summary for {label}:")
              for severity in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]:
                  print(f"{severity}: {counts[severity]}")
              packages = Counter()
              for result in data.get("Results", []):
                  for vuln in result.get("Vulnerabilities", []) or []:
                      pkg = vuln.get("PkgName")
                      if pkg:
                          packages[pkg] += 1
              if packages:
                  print("Top 10 packages by vulnerability count:")
                  for name, count in packages.most_common(10):
                      print(f"{name}: {count}")
              else:
                  print("Top 10 packages by vulnerability count: none found")
          if missing:
              sys.exit(2)
          sys.exit(0)
          PY

      - name: Upload Trivy reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: trivy-reports
          path: |
            trivy-cleanwithsnapshot-*.json

      - name: Fail if Trivy gate hit (HIGH/CRITICAL)
        if: always()
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          reports = [
              Path("trivy-cleanwithsnapshot-api.json"),
              Path("trivy-cleanwithsnapshot-web.json"),
          ]

          def has_high_critical(report: Path) -> bool:
              if not report.exists():
                  return False
              data = json.loads(report.read_text())
              for r in data.get("Results", []) or []:
                  for v in (r.get("Vulnerabilities") or []):
                      if v.get("Severity") in ("CRITICAL", "HIGH"):
                          # ignore-unfixed уже применён Trivy action'ом,
                          # но если вдруг нет — можно дополнительно проверять FixedVersion.
                          return True
              return False

          hit = any(has_high_critical(p) for p in reports)
          raise SystemExit(1 if hit else 0)
          PY


  secrets-scan:
    name: Security - Secrets Scan (Gitleaks)
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  infra:
    name: Infrastructure - Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create ephemeral .env for compose validation
        run: |
          cat > .env <<'EOF'
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          EOF

      - name: Validate docker-compose.yml
        run: |
          echo "Validating docker-compose configuration..."
          docker compose config > /dev/null
          echo "✓ docker-compose.yml is valid"

      - name: Cleanup ephemeral .env
        run: rm -f .env

      - name: Check for shell scripts
        run: |
          if [ -d "ops" ]; then
            echo "Checking bash scripts in ops/..."
            find ops -name "*.sh" -type f -exec bash -n {} \; -print
            echo "✓ All bash scripts have valid syntax"
          else
            echo "ℹ No ops/ directory found, skipping bash validation"
          fi

  smoke-compose:
    name: Smoke - Docker Compose
    runs-on: ubuntu-latest
    needs: [api, web]
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot-ci

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create CI .env for compose
        run: |
          cat > .env <<'EOF'
          APP_ENV=dev
          TESTING=true
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          DATABASE_URL=postgresql+psycopg://postgres:postgres@db:5432/cleaning
          NEXT_PUBLIC_API_BASE_URL=http://api:8000
          EOF

      - name: Start Docker Compose stack (smoke)
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d --wait db redis api web

      - name: Run smoke tests
        run: ./ops/smoke.sh
        env:
          API_BASE_URL: http://localhost:8000
          WEB_BASE_URL: http://localhost:3000

      - name: Capture compose logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml ps > compose-ps.txt
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --no-color > compose.log

      - name: Upload compose logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: compose-smoke-logs
          path: |
            compose.log
            compose-ps.txt

      - name: Tear down Docker Compose stack
        if: always()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v

      - name: Cleanup CI .env
        if: always()
        run: rm -f .env
