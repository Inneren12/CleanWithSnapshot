name: CI

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  api:
    name: API - Build & Test
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version-file: .python-version

      - name: Display Python version
        run: python --version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          PIP_ONLY_BINARY=greenlet pip install -r requirements.txt -c constraints.txt

      - name: Verify greenlet wheel install
        run: python -c "import greenlet, sys; print(sys.version); print(greenlet.__version__)"

      - name: Pip check
        run: pip check

      - name: Pip freeze (debug)
        run: pip freeze

      - name: Install pytest-cov
        run: python -m pip install pytest-cov==5.0.0 --no-cache-dir

      - name: Alembic heads preflight (single-head guard)
        run: |
          set -euo pipefail
          heads=$(alembic heads -q || true)
          count=$(printf "%s\n" "$heads" | sed '/^$/d' | wc -l | tr -d ' ')
          if [ "$count" -gt 1 ]; then
            echo "❌ Multiple Alembic heads detected ($count). Merge heads before running migration tests."
            echo "Heads:"
            printf "%s\n" "$heads"
            exit 1
          fi
          echo "✅ Alembic head OK: ${heads}"

      - name: Lint (syntax guard)
        run: |
          python -m pip install ruff==0.6.5
          ruff check app tests --select E9

      - name: Guard boolean defaults in migrations
        run: |
          set -euo pipefail
          if rg -n "Boolean\\(\\).*server_default=(sa.text\\(\\\"[01]\\\"\\)|\\\"[01]\\\")|BOOLEAN DEFAULT [01]" alembic; then
            echo "❌ Boolean defaults must use true/false, not 0/1."
            exit 1
          fi

      - name: Run unit tests with coverage
        working-directory: .
        run: |
          # Run tests excluding smoke and postgres markers (unit tests that work with SQLite)
          # Also ignore smoke folder entirely as belt-and-suspenders
          pytest -v -m "not smoke and not postgres" --ignore=backend/tests/smoke --tb=short --cov=backend/app --cov-report=xml --cov-report=term -W default 2>&1 | tee pytest-warnings.log
        env:
          # CI-safe environment variables (no secrets)
          APP_ENV: "dev"
          TESTING: "true"
          DATABASE_URL: "sqlite+aiosqlite:///:memory:"
          PYTHONPATH: "backend"

      - name: Upload coverage report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: pytest-coverage
          path: coverage.xml

      - name: Run warnings audit
        if: always()
        working-directory: backend
        run: |
          mkdir -p warnings-audit
          python scripts/warnings_audit.py --log ../pytest-warnings.log --out warnings-audit --gate fail
        env:
          PYTHONPATH: "."

      - name: Upload warnings audit report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: warnings-audit
          path: |
            backend/warnings-audit/
            pytest-warnings.log

  web:
    name: Web - Build
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: web

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Node.js
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version-file: .nvmrc

      - name: Display Node version
        run: node --version

      - name: Verify Node runtime matches .nvmrc
        run: |
          expected=$(cat ../.nvmrc)
          actual=$(node --version | sed 's/^v//')
          if [ "$actual" != "$expected" ]; then
            echo "Node version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache npm dependencies
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('web/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install dependencies
        run: npm install

      - name: Install ephemeral TypeScript test deps
        run: npm i -D --no-save --no-package-lock vitest @testing-library/react @testing-library/jest-dom jsdom

      - name: Typecheck
        run: npx tsc --noEmit

      - name: Lint (if available)
        run: npm run lint --if-present

      - name: Build application
        run: npm run build
        env:
          # CI-safe environment variable for Next.js build
          NEXT_PUBLIC_API_BASE_URL: "http://localhost:8000"

  web-vitest:
    name: Web - Vitest (Coverage)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: web
    env:
      CI: "true"
      NODE_ENV: "test"
      TZ: "UTC"

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Node.js
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version-file: .nvmrc

      - name: Install dependencies
        run: npm install

      - name: Install ephemeral Vitest deps
        run: npm install --no-save --no-package-lock vitest @vitest/coverage-v8 @testing-library/react @testing-library/jest-dom jsdom@22

      - name: Run Vitest with coverage
        run: npx vitest run --coverage --pool=threads

      - name: Upload Vitest coverage artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: vitest-coverage
          path: web/coverage/

  api-prod-config:
    name: API - Prod Config Validation
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          PIP_ONLY_BINARY=greenlet pip install -r requirements.txt -c constraints.txt

      - name: Verify greenlet wheel install
        run: python -c "import greenlet, sys; print(sys.version); print(greenlet.__version__)"

      - name: Pip check
        run: pip check

      - name: Validate prod config requirements
        run: |
          python -c "from app.settings import Settings; s = Settings(); print(f'✓ Prod config validation passed: APP_ENV={s.app_env}')"
        env:
          # Prod mode with CI-safe dummy secrets (validates prod enforcement still works)
          APP_ENV: "prod"
          TESTING: "false"
          SECRETS_BACKEND: "aws_secrets_manager"
          AWS_REGION: "us-east-1"
          AWS_DEFAULT_REGION: "us-east-1"
          AWS_SECRETS_MANAGER_REGION: "us-east-1"
          AWS_SECRETS_MANAGER_SECRET_ID: "ci-dummy"
          AWS_SECRETS_MANAGER_SECRET_JSON: |
            {"AUTH_SECRET_KEY":"ci-auth-secret-not-default-12345678","CLIENT_PORTAL_SECRET":"ci-client-secret-not-default-12345678","WORKER_PORTAL_SECRET":"ci-worker-secret-not-default-12345678","ADMIN_PROXY_AUTH_SECRET":"ci-admin-proxy-secret-not-default-12345678"}
          METRICS_ENABLED: "false"
          STRICT_CORS: "false"

  security:
    name: Security - Bandit Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat .python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Install Bandit
        run: python -m pip install bandit==1.7.9 --no-cache-dir

      - name: Run Bandit (high severity)
        run: |
          set -o pipefail
          bandit -r backend/app --severity-level high -f json -o bandit-report.json --exit-zero 2>&1 | tee bandit.log
          status=${PIPESTATUS[0]}
          if [ ! -f bandit-report.json ]; then
            echo '{"error":"bandit failed. See bandit.log"}' > bandit-report.json
          fi
          exit "$status"

      - name: Upload Bandit report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: bandit-report
          path: |
            bandit-report.json
            bandit.log

  rls-audit:
    name: Security - RLS Coverage Audit
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend
    env:
      DATABASE_URL: postgresql+psycopg://postgres:postgres@localhost:5432/cleaning
      APP_ENV: dev
      TESTING: true
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: cleaning
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version-file: .python-version

      - name: Verify Python runtime matches .python-version
        run: |
          expected=$(cat ../.python-version)
          actual=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          if [ "$actual" != "$expected" ]; then
            echo "Python version mismatch: expected ${expected}, got ${actual}"
            exit 1
          fi

      - name: Cache pip dependencies
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt', 'backend/constraints.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          PIP_ONLY_BINARY=greenlet pip install -r requirements.txt -c constraints.txt
          python -m pip install "alembic>=1.13"

      - name: Verify greenlet wheel install
        run: python -c "import greenlet, sys; print(sys.version); print(greenlet.__version__)"

      - name: Pip check
        run: pip check

      - name: Apply migrations
        run: python -m alembic -c alembic_rls_audit.ini upgrade head

      - name: Run RLS coverage audit
        run: |
          python scripts/audit_rls_coverage.py --output rls-audit.md --fail-on-core-missing

      - name: Upload RLS audit report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: rls-audit-report
          path: backend/rls-audit.md

  container-scan:
    name: Security - Trivy Image Scan
    runs-on: ubuntu-latest
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot
      TRIVY_SEVERITY: "CRITICAL"
      SYFT_VERSION: "v1.40.1"

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Build api and web images
        run: docker compose build api web

      - name: Capture built image IDs
        run: |
          API_IMAGE_ID=$(docker image inspect -f '{{.Id}}' cleanwithsnapshot-api:ci)
          WEB_IMAGE_ID=$(docker image inspect -f '{{.Id}}' cleanwithsnapshot-web:ci)
          if [ -z "${API_IMAGE_ID}" ] || [ -z "${WEB_IMAGE_ID}" ]; then
            echo "Failed to resolve image IDs. api=${API_IMAGE_ID} web=${WEB_IMAGE_ID}"
            exit 1
          fi
          echo "API_IMAGE_ID=${API_IMAGE_ID}" >> "$GITHUB_ENV"
          echo "WEB_IMAGE_ID=${WEB_IMAGE_ID}" >> "$GITHUB_ENV"
          {
            echo "api cleanwithsnapshot-api:ci ${API_IMAGE_ID}"
            echo "web cleanwithsnapshot-web:ci ${WEB_IMAGE_ID}"
            docker image inspect --format='{{.RepoTags}} {{.Id}}' cleanwithsnapshot-api:ci
            docker image inspect --format='{{.RepoTags}} {{.Id}}' cleanwithsnapshot-web:ci
          } > built-image-ids.txt

      - name: Save local images to TAR
        run: |
          echo "Saving images to tar for disconnected scanning..."
          docker save cleanwithsnapshot-api:ci -o api-image.tar
          docker save cleanwithsnapshot-web:ci -o web-image.tar
          ls -lh *.tar

      - name: Verify api image wheel/jaraco versions
        run: |
          docker run --rm cleanwithsnapshot-api:ci \
            python -c "import importlib.metadata as m; print('wheel', m.version('wheel')); print('jaraco.context', m.version('jaraco.context'))"

      - name: Inspect api image site-packages for duplicates
        run: |
          docker run --rm cleanwithsnapshot-api:ci \
            python -c "import sys, importlib.metadata as m; print('sys.path:', *sys.path, sep='\\n  '); print('wheel:', m.version('wheel')); print('jaraco.context:', m.version('jaraco.context'))"
          docker run --rm cleanwithsnapshot-api:ci sh -lc "\
            set -e; \
            echo '=== FIND wheel/jaraco dist-info ==='; \
            find / -type d \\( -name 'wheel-*.dist-info' -o -name 'jaraco.context-*.dist-info' \\) 2>/dev/null | sort | sed 's/^/FOUND: /'; \
            echo '=== DONE ==='"

      - name: Install Trivy
        uses: aquasecurity/setup-trivy@v0.2.2
        with:
          version: v0.58.1

      - name: Install Syft
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin ${{ env.SYFT_VERSION }}
          syft --version

      # Use tar-based scanning to avoid Docker API vs Client version mismatches 
      # when running inside actions, and to ensure stable scanning of the exact built artifacts.
      - name: Scan API Image (Trivy)
        run: |
          set +e
          IMAGE_TAR="api-image.tar"
          BASE_NAME="cleanwithsnapshot-api"
          
          echo "Scanning ${IMAGE_TAR}..."
          ls -lh ${IMAGE_TAR}
          
          # JSON Report (Full)
          trivy image --input ${IMAGE_TAR} \
            --format json \
            --output trivy-${BASE_NAME}.json \
            --timeout 15m 2> trivy-api.log
          EXIT_JSON=$?
          
          # SARIF Report
          trivy image --input ${IMAGE_TAR} \
            --format sarif \
            --output trivy-${BASE_NAME}.sarif \
            --timeout 15m >> trivy-api.log 2>&1
            
          # SBOM (SPDX)
          trivy image --input ${IMAGE_TAR} \
            --format spdx-json \
            --output sbom-trivy-${BASE_NAME}.json \
            --timeout 15m >> trivy-api.log 2>&1
            
          # Determine status
          if [ $EXIT_JSON -ne 0 ]; then
             echo "❌ Trivy failed to run on API image (Exit: $EXIT_JSON)"
             echo '{"_tool_error": "Trivy execution failed"}' > trivy-${BASE_NAME}.json
             TRIVY_API_EXIT_CODE=2
             
             echo "=== Trivy Debug Log (First 50 lines) ==="
             trivy --version
             head -n 50 trivy-api.log
          else
             # Check for CRITICALs
             trivy image --input ${IMAGE_TAR} --severity CRITICAL --exit-code 1 --format table > /dev/null 2>> trivy-api.log
             if [ $? -eq 1 ]; then
                echo "⚠️ CRITICAL vulnerabilities found in API image"
                TRIVY_API_EXIT_CODE=1
             else
                echo "✅ API image scan clean (no CRITICALs)"
                TRIVY_API_EXIT_CODE=0
             fi
          fi
          
          echo "TRIVY_API_EXIT_CODE=$TRIVY_API_EXIT_CODE" >> $GITHUB_ENV
          set -e

      - name: Scan Web Image (Trivy)
        run: |
          set +e
          IMAGE_TAR="web-image.tar"
          BASE_NAME="cleanwithsnapshot-web"
          
          echo "Scanning ${IMAGE_TAR}..."
          ls -lh ${IMAGE_TAR}
          
          # JSON Report (Full)
          trivy image --input ${IMAGE_TAR} \
            --format json \
            --output trivy-${BASE_NAME}.json \
            --timeout 15m 2> trivy-web.log
          EXIT_JSON=$?
          
          # SARIF Report
          trivy image --input ${IMAGE_TAR} \
            --format sarif \
            --output trivy-${BASE_NAME}.sarif \
            --timeout 15m >> trivy-web.log 2>&1
            
          # SBOM (SPDX)
          trivy image --input ${IMAGE_TAR} \
            --format spdx-json \
            --output sbom-trivy-${BASE_NAME}.json \
            --timeout 15m >> trivy-web.log 2>&1
            
          # Determine status
          if [ $EXIT_JSON -ne 0 ]; then
             echo "❌ Trivy failed to run on Web image (Exit: $EXIT_JSON)"
             echo '{"_tool_error": "Trivy execution failed"}' > trivy-${BASE_NAME}.json
             TRIVY_WEB_EXIT_CODE=2
             
             echo "=== Trivy Debug Log (First 50 lines) ==="
             trivy --version
             head -n 50 trivy-web.log
          else
             # Check for CRITICALs
             trivy image --input ${IMAGE_TAR} --severity CRITICAL --exit-code 1 --format table > /dev/null 2>> trivy-web.log
             if [ $? -eq 1 ]; then
                echo "⚠️ CRITICAL vulnerabilities found in Web image"
                TRIVY_WEB_EXIT_CODE=1
             else
                echo "✅ Web image scan clean (no CRITICALs)"
                TRIVY_WEB_EXIT_CODE=0
             fi
          fi
          
          echo "TRIVY_WEB_EXIT_CODE=$TRIVY_WEB_EXIT_CODE" >> $GITHUB_ENV
          set -e

      - name: Generate SBOM (api, Syft SPDX)
        run: syft docker-archive:api-image.tar -o spdx-json > sbom-cleanwithsnapshot-api.json

      - name: Generate SBOM (web, Syft SPDX)
        run: syft docker-archive:web-image.tar -o spdx-json > sbom-cleanwithsnapshot-web.json
      
      - name: Upload Container Scan Artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: container-sboms
          path: |
            trivy-cleanwithsnapshot-*.json
            trivy-cleanwithsnapshot-*.sarif
            sbom-trivy-cleanwithsnapshot-*.json
            sbom-cleanwithsnapshot-*.json
            built-image-ids.txt
            trivy-*.log
          retention-days: 30

      - name: Enforce Trivy Gate
        if: always()
        run: |
          tool_failure=0
          vuln_failure=0

          check_trivy() {
            local label="$1"
            local exit_code="$2"
            local report="$3"
            
            if [ -z "$exit_code" ]; then
              echo "⚠️ Exit code missing for ${label}. Assuming tool failure."
              exit_code=2
            fi

            if [ ! -s "$report" ]; then
              echo "Trivy failure: missing report for ${label} (${report})."
              ls -lh "$report" || true
              tool_failure=1
            elif grep -q "_tool_error" "$report"; then
              echo "Trivy tool error detected in report for ${label}."
              cat "$report"
              tool_failure=1
            fi

            if [ "$exit_code" -eq 2 ]; then
               echo "Trivy explicitly exited with 2 for ${label} (Scanner failure)."
               tool_failure=1
            elif [ "$exit_code" -eq 1 ]; then
               echo "CRITICAL vulnerabilities found for ${label}."
               vuln_failure=1
            elif [ "$exit_code" -eq 0 ]; then
               echo "Trivy scan clean for ${label}."
            else
               echo "Unknown exit code ${exit_code} for ${label}."
               tool_failure=1
            fi
          }

          check_trivy "api" "$TRIVY_API_EXIT_CODE" "trivy-cleanwithsnapshot-api.json"
          check_trivy "web" "$TRIVY_WEB_EXIT_CODE" "trivy-cleanwithsnapshot-web.json"

          if [ "$tool_failure" -eq 1 ]; then
            echo "Trivy tool failure"
            exit 2
          fi
          if [ "$vuln_failure" -eq 1 ]; then
            echo "CRITICAL vulnerabilities found"
            exit 1
          fi
          echo "Trivy scan passed."

  grype-scan:
    name: Security - Grype Image Scan
    runs-on: ubuntu-latest
    needs: container-scan
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot
      GRYPE_FAIL_ON: "critical"
      GRYPE_VERSION: "v0.105.0"

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Download Container SBOMs
        uses: actions/download-artifact@fa0a91b85d4f404e8442c7e9977684ae160f5450 # v4
        with:
          name: container-sboms

      - name: Validate Grype severity cutoff
        run: |
          case "${GRYPE_FAIL_ON}" in
            critical|high|medium|low)
              ;;
            *)
              echo "Invalid GRYPE_FAIL_ON value: ${GRYPE_FAIL_ON}"
              exit 1
              ;;
          esac
          echo "Grype severity cutoff: ${GRYPE_FAIL_ON}"
          echo "Grype version: ${GRYPE_VERSION}"
          ls -lh sbom-cleanwithsnapshot-*.json

      - name: Install Grype
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin ${{ env.GRYPE_VERSION }}
          grype --version

      # Use Syft SBOMs for stability (avoids docker-archive exit 2 flakiness in Grype)
      - name: Scan api SBOM (Grype JSON)
        id: grype_api
        run: |
          set +e
          touch grype-cleanwithsnapshot-api.json
          echo "Running Grype on API SBOM..."
          grype sbom:sbom-cleanwithsnapshot-api.json -o json > grype-cleanwithsnapshot-api.json --fail-on ${{ env.GRYPE_FAIL_ON }}
          exit_code=$?
          set -e
          echo "GRYPE_API_EXIT_CODE=$exit_code" >> "$GITHUB_ENV"

          if [ "$exit_code" -eq 2 ]; then
            echo "⚠️ Grype failed (exit 2). Debug info:"
            grype version
            ls -lh sbom-cleanwithsnapshot-api.json
            echo "first 30 lines of SBOM:"
            head -n 30 sbom-cleanwithsnapshot-api.json
          fi

          if [ ! -s grype-cleanwithsnapshot-api.json ]; then
            echo '{"_tool_error": "Grype produced empty output"}' > grype-cleanwithsnapshot-api.json
          fi
          exit 0

      - name: Scan web SBOM (Grype JSON)
        id: grype_web
        run: |
          set +e
          touch grype-cleanwithsnapshot-web.json
          echo "Running Grype on Web SBOM..."
          grype sbom:sbom-cleanwithsnapshot-web.json -o json > grype-cleanwithsnapshot-web.json --fail-on ${{ env.GRYPE_FAIL_ON }}
          exit_code=$?
          set -e
          echo "GRYPE_WEB_EXIT_CODE=$exit_code" >> "$GITHUB_ENV"

          if [ "$exit_code" -eq 2 ]; then
            echo "⚠️ Grype failed (exit 2). Debug info:"
            grype version
            ls -lh sbom-cleanwithsnapshot-web.json
            echo "first 30 lines of SBOM:"
            head -n 30 sbom-cleanwithsnapshot-web.json
          fi

          if [ ! -s grype-cleanwithsnapshot-web.json ]; then
            echo '{"_tool_error": "Grype produced empty output"}' > grype-cleanwithsnapshot-web.json
          fi
          exit 0

      - name: Enforce Grype severity gate
        if: always()
        run: |
          tool_failure=0
          vuln_failure=0

          echo "Generated Grype reports:"
          ls -lh grype-*.json sbom-*.json || true

          check_grype() {
            local label="$1"
            local exit_code="$2"
            local report="$3"
            
            if [ -z "$exit_code" ]; then
              echo "⚠️ Exit code missing for ${label}. Assuming tool failure."
              exit_code=2
            fi

            if [ ! -s "$report" ]; then
              echo "Grype tool failure: missing report for ${label} (${report})."
              tool_failure=1
            elif grep -q "_tool_error" "$report"; then
              echo "Grype tool error detected in report for ${label}."
              cat "$report"
              tool_failure=1
            fi

            if [ "$exit_code" -eq 2 ]; then
               echo "Grype explicitly exited with 2 for ${label} (Scanner failure)."
               tool_failure=1
            elif [ "$exit_code" -eq 1 ]; then
               echo "Grype found vulnerabilities above cutoff for ${label}."
               vuln_failure=1
            elif [ "$exit_code" -eq 0 ]; then
               echo "Grype scan clean for ${label}."
            else
               echo "Unknown exit code ${exit_code} for ${label}."
               tool_failure=1
            fi
          }

          check_grype "api" "$GRYPE_API_EXIT_CODE" "grype-cleanwithsnapshot-api.json"
          check_grype "web" "$GRYPE_WEB_EXIT_CODE" "grype-cleanwithsnapshot-web.json"

          if [ "$tool_failure" -eq 1 ]; then
            echo "Grype tool failure"
            exit 2
          fi
          if [ "$vuln_failure" -eq 1 ]; then
            echo "${GRYPE_FAIL_ON^^} vulnerabilities found"
            exit 1
          fi
          echo "Grype scan passed with no ${GRYPE_FAIL_ON} findings."

      - name: Upload Grype reports
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: grype-reports
          path: |
            grype-cleanwithsnapshot-*.json
            grype-cleanwithsnapshot-*.sarif
          retention-days: 30


  secrets-scan:
    name: Security - Secrets Scan (Gitleaks)
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          fetch-depth: 0

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@ff98106e4c7b2bc287b24eaf42907196329070c7 # v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  infra:
    name: Infrastructure - Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Create ephemeral .env for compose validation
        run: |
          cat > .env <<'EOF'
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          EOF

      - name: Validate docker-compose.yml
        run: |
          echo "Validating docker-compose configuration..."
          docker compose config > /dev/null
          echo "✓ docker-compose.yml is valid"

      - name: Cleanup ephemeral .env
        run: rm -f .env

      - name: Check for shell scripts
        run: |
          if [ -d "ops" ]; then
            echo "Checking bash scripts in ops/..."
            find ops -name "*.sh" -type f -exec bash -n {} \; -print
            echo "✓ All bash scripts have valid syntax"
          else
            echo "ℹ No ops/ directory found, skipping bash validation"
          fi

  smoke-compose:
    name: Smoke - Docker Compose
    runs-on: ubuntu-latest
    needs: [api, web]
    env:
      COMPOSE_PROJECT_NAME: cleanwithsnapshot-ci

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Create CI .env for compose
        run: |
          cat > .env <<'EOF'
          APP_ENV=dev
          TESTING=true
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=postgres
          POSTGRES_DB=cleaning
          DATABASE_URL=postgresql+psycopg://postgres:postgres@db:5432/cleaning
          NEXT_PUBLIC_API_BASE_URL=http://api:8000
          EOF

      - name: Start Docker Compose stack (smoke)
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d --wait db redis api web

      - name: Run smoke tests
        run: ./ops/smoke.sh
        env:
          API_BASE_URL: http://localhost:8000
          WEB_BASE_URL: http://localhost:3000

      - name: Capture compose logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml ps > compose-ps.txt
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --no-color > compose.log

      - name: Upload compose logs
        if: failure()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: compose-smoke-logs
          path: |
            compose.log
            compose-ps.txt

      - name: Tear down Docker Compose stack
        if: always()
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v

      - name: Cleanup CI .env
        if: always()
        run: rm -f .env

  perf-baseline:
    name: Performance - Baseline Comparison (Warn-only)
    runs-on: ubuntu-latest
    if: ${{ vars.PERF_BASE_URL != '' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version-file: .python-version

      - name: Install k6
        uses: grafana/setup-k6-action@ffe7d7290dfa715e48c2ccc924d068444c94bde2 # v1

      - name: Preflight perf baseline target
        env:
          BASE_URL: ${{ vars.PERF_BASE_URL }}
        run: |
          if ! curl -fsS --max-time 2 "${BASE_URL}/healthz" >/dev/null; then
            echo "Perf baseline skipped: ${BASE_URL} unreachable."
            echo "PERF_SKIP=1" >> "$GITHUB_ENV"
            exit 0
          fi

      - name: Run healthz load test + baseline compare
        if: env.PERF_SKIP != '1'
        env:
          BASE_URL: ${{ vars.PERF_BASE_URL }}
        run: |
          k6 run --no-thresholds --summary-export k6-healthz.json load-tests/k6/healthz.js
          python load-tests/compare_baseline.py --scenario healthz --results k6-healthz.json --mode warn

      - name: Run admin load test + baseline compare
        if: env.PERF_SKIP != '1'
        env:
          BASE_URL: ${{ vars.PERF_BASE_URL }}
          ADMIN_USER: ${{ secrets.PERF_ADMIN_USER }}
          ADMIN_PASSWORD: ${{ secrets.PERF_ADMIN_PASSWORD }}
          ADMIN_AUTH_HEADER: ${{ secrets.PERF_ADMIN_AUTH_HEADER }}
        run: |
          if [ -z "${ADMIN_AUTH_HEADER:-}" ] && { [ -z "${ADMIN_USER:-}" ] || [ -z "${ADMIN_PASSWORD:-}" ]; }; then
            echo "Skipping admin_list scenario: admin credentials not provided."
            exit 0
          fi
          k6 run --no-thresholds --summary-export k6-admin.json load-tests/k6/admin_list.js
          python load-tests/compare_baseline.py --scenario admin_list --results k6-admin.json --mode warn

      - name: Run booking flow load test + baseline compare
        if: env.PERF_SKIP != '1'
        env:
          BASE_URL: ${{ vars.PERF_BASE_URL }}
          BOOKING_CAPTCHA_TOKEN: ${{ secrets.PERF_BOOKING_CAPTCHA_TOKEN }}
        run: |
          k6 run --no-thresholds --summary-export k6-booking.json load-tests/k6/booking_flow.js
          python load-tests/compare_baseline.py --scenario booking_flow --results k6-booking.json --mode warn
